{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:21:27.631109Z","iopub.status.busy":"2024-02-28T08:21:27.630721Z","iopub.status.idle":"2024-02-28T08:21:52.224676Z","shell.execute_reply":"2024-02-28T08:21:52.223455Z","shell.execute_reply.started":"2024-02-28T08:21:27.631078Z"},"id":"EWC7oBePZFbI","outputId":"0e5738ad-74a0-46b4-e2c4-a9d448cf07cc","trusted":true},"outputs":[],"source":["# !pip install -q transformers\n","! pip install -U accelerate\n","! pip install -U transformers "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:21:52.227151Z","iopub.status.busy":"2024-02-28T08:21:52.226819Z","iopub.status.idle":"2024-02-28T08:22:16.482604Z","shell.execute_reply":"2024-02-28T08:22:16.481587Z","shell.execute_reply.started":"2024-02-28T08:21:52.227122Z"},"id":"d_yAk9NnerWy","outputId":"57b8bc68-4cc1-4438-ecc0-3147df4f70e2","trusted":true},"outputs":[],"source":["!pip install -q datasets jiwer\n","!pip install gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:16.484710Z","iopub.status.busy":"2024-02-28T08:22:16.484300Z","iopub.status.idle":"2024-02-28T08:22:18.981742Z","shell.execute_reply":"2024-02-28T08:22:18.980696Z","shell.execute_reply.started":"2024-02-28T08:22:16.484675Z"},"id":"m-D6BCnxetDp","outputId":"c5912c8f-96bf-456a-c751-dda7a805698f","trusted":true},"outputs":[],"source":["# !gdown 1lR0b1QBIsXk9JqL9__HgJQi0PdWeNxKi\n","!gdown 1b4fCTrnfKnR0GHm1XCve9nhy7JyrqahR"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:18.984685Z","iopub.status.busy":"2024-02-28T08:22:18.984379Z","iopub.status.idle":"2024-02-28T08:22:18.989254Z","shell.execute_reply":"2024-02-28T08:22:18.988260Z","shell.execute_reply.started":"2024-02-28T08:22:18.984658Z"},"id":"sPxO8Xb7kFal","outputId":"64ac32c3-9d16-4404-d6c1-38e05fdf7d45","trusted":true},"outputs":[],"source":["# !unzip -q /kaggle/working/training_data.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:18.990642Z","iopub.status.busy":"2024-02-28T08:22:18.990362Z","iopub.status.idle":"2024-02-28T08:22:29.343028Z","shell.execute_reply":"2024-02-28T08:22:29.342112Z","shell.execute_reply.started":"2024-02-28T08:22:18.990619Z"},"id":"KUv_34FfkXp8","outputId":"f0677b75-ce4d-4c9d-be79-f002d7af1ad1","trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_fwf('/kaggle/working/train_gt.txt', header=None)\n","# df.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\n","\n","# df['file_name'] = df['file_name'].apply(lambda x: x + 'g' if x.endswith('jp') else x)\n","for index, row in df.iterrows():\n","  input = row\n","  input = input[0].split()\n","  df.at[index, 0] = input[0]  # Assign the first part to the first column\n","  df.at[index, 1] = ' '.join(input[1:])  # Assign the rest to the second column\n","# print(df['file_name'][26909])\n","df.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:29.344672Z","iopub.status.busy":"2024-02-28T08:22:29.344329Z","iopub.status.idle":"2024-02-28T08:22:29.928690Z","shell.execute_reply":"2024-02-28T08:22:29.927778Z","shell.execute_reply.started":"2024-02-28T08:22:29.344646Z"},"id":"Gz_-i_yyM_oH","outputId":"d103a87e-ce28-46df-ac41-80c8d5d8f7df","trusted":true},"outputs":[],"source":["# prompt: i want to see a few example image in /content/new_train print it to see about 2 image\n","\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Get the path to the new_train directory\n","new_train_path = \"/kaggle/working/new_train\"\n","\n","# Get a list of all files in the new_train directory\n","files = os.listdir(new_train_path)\n","\n","# Select two random files from the list\n","\n","# Load and display the images\n","i = 0\n","for file in files:\n","    print(file)\n","    image_path = os.path.join(new_train_path, file)\n","    image = plt.imread(image_path)\n","    plt.imshow(image)\n","    plt.show()\n","    i += 1\n","    if i == 2:\n","      break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:29.930819Z","iopub.status.busy":"2024-02-28T08:22:29.930113Z","iopub.status.idle":"2024-02-28T08:22:29.967865Z","shell.execute_reply":"2024-02-28T08:22:29.966918Z","shell.execute_reply.started":"2024-02-28T08:22:29.930784Z"},"id":"l2gw0IcKQWLd","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, test_df = train_test_split(df, test_size=0.2)\n","# we reset the indices to start from zero\n","eval_df, test_df = train_test_split(test_df, test_size=0.5)\n","train_df.reset_index(drop=True, inplace=True)\n","eval_df.reset_index(drop=True, inplace=True)\n","test_df.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:29.969560Z","iopub.status.busy":"2024-02-28T08:22:29.969153Z","iopub.status.idle":"2024-02-28T08:22:29.980310Z","shell.execute_reply":"2024-02-28T08:22:29.979386Z","shell.execute_reply.started":"2024-02-28T08:22:29.969503Z"},"id":"z1WwR_DSQ2hi","trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","class VOCRDataset(Dataset):\n","    def __init__(self, root_dir, df, processor, transform, tokenizer, max_target_length=128):\n","        self.root_dir = root_dir\n","        self.df = df\n","        self.processor = processor\n","        self.transform = transform\n","        self.max_target_length = max_target_length\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        # get file name + text\n","        file_name = self.df['file_name'][idx]\n","        text = self.df['text'][idx]\n","        # prepare image (i.e. resize + normalize)\n","        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n","        # add labels (input_ids) by encoding the text\n","        # labels = self.processor.tokenizer(text,\n","        #                                   padding=\"max_length\",\n","        #                                   max_length=self.max_target_length).input_ids\n","        labels = self.tokenizer(text,\n","                                          padding=\"max_length\",\n","                                          max_length=self.max_target_length).input_ids\n","        # important: make sure that PAD tokens are ignored by the loss function\n","        # labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n","        labels = [label if label != self.tokenizer.pad_token_id else -100 for label in labels]\n","\n","        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n","        return encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:29.981970Z","iopub.status.busy":"2024-02-28T08:22:29.981635Z","iopub.status.idle":"2024-02-28T08:22:30.898144Z","shell.execute_reply":"2024-02-28T08:22:30.897189Z","shell.execute_reply.started":"2024-02-28T08:22:29.981940Z"},"id":"HvSkoGRETcoF","trusted":true},"outputs":[],"source":["from transformers import AutoImageProcessor, ViTModel\n","from torchvision import transforms\n","from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n","\n","train_dataset = VOCRDataset(root_dir='/kaggle/working/new_train/',\n","#                            df=train_df,                                                       \n","                            df=test_df,\n","                           processor=processor,\n","                            transform = transform,\n","                            tokenizer=tokenizer)\n","eval_dataset = VOCRDataset(root_dir='/kaggle/working/new_train/',\n","                           df=eval_df,\n","                           processor=processor,\n","                            transform = transform,\n","                           tokenizer=tokenizer)\n","test_dataset = VOCRDataset(root_dir='/kaggle/working/new_train/',\n","                           df=test_df,\n","                           processor=processor,\n","                            transform = transform,\n","                           tokenizer=tokenizer)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:30.902236Z","iopub.status.busy":"2024-02-28T08:22:30.901936Z","iopub.status.idle":"2024-02-28T08:22:30.907475Z","shell.execute_reply":"2024-02-28T08:22:30.906563Z","shell.execute_reply.started":"2024-02-28T08:22:30.902210Z"},"id":"eYImh6UxTej7","outputId":"891baec1-d5db-464e-e579-052daa5e1b9c","trusted":true},"outputs":[],"source":["print(\"Number of training examples:\", len(train_dataset))\n","print(\"Number of validation examples:\", len(eval_dataset))\n","print(\"Number of test examples:\", len(test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:30.908824Z","iopub.status.busy":"2024-02-28T08:22:30.908553Z","iopub.status.idle":"2024-02-28T08:22:30.934369Z","shell.execute_reply":"2024-02-28T08:22:30.933500Z","shell.execute_reply.started":"2024-02-28T08:22:30.908801Z"},"id":"U2defMSOV50k","outputId":"e2742533-3a12-420a-eb5c-7f43ae40826d","trusted":true},"outputs":[],"source":["print(type(train_dataset))\n","print(train_dataset)\n","encoding = train_dataset[0]\n","for k,v in encoding.items():\n","  print(k, v.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:30.935737Z","iopub.status.busy":"2024-02-28T08:22:30.935450Z","iopub.status.idle":"2024-02-28T08:22:30.951325Z","shell.execute_reply":"2024-02-28T08:22:30.950482Z","shell.execute_reply.started":"2024-02-28T08:22:30.935713Z"},"id":"FLqsKIaDV6NO","outputId":"fb507c62-965f-4e08-9fbb-8d1897e88d86","trusted":true},"outputs":[],"source":["image = Image.open(train_dataset.root_dir + train_df['file_name'][0]).convert(\"RGB\")\n","image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:30.952652Z","iopub.status.busy":"2024-02-28T08:22:30.952372Z","iopub.status.idle":"2024-02-28T08:22:30.960409Z","shell.execute_reply":"2024-02-28T08:22:30.959548Z","shell.execute_reply.started":"2024-02-28T08:22:30.952628Z"},"id":"_gadpE9LV6bs","outputId":"1e8e6b1a-dc8c-4370-8718-3957592825c7","trusted":true},"outputs":[],"source":["labels = encoding['labels']\n","labels[labels == -100] = tokenizer.pad_token_id\n","label_str = tokenizer.decode(labels, skip_special_tokens=True)\n","print(label_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:30.962216Z","iopub.status.busy":"2024-02-28T08:22:30.961712Z","iopub.status.idle":"2024-02-28T08:22:32.346370Z","shell.execute_reply":"2024-02-28T08:22:32.345626Z","shell.execute_reply.started":"2024-02-28T08:22:30.962192Z"},"id":"e21ECqm4i1on","outputId":"b7371ff4-a630-4edb-d82c-3b9bd9aae5ce","trusted":true},"outputs":[],"source":["\n","from transformers import VisionEncoderDecoderModel\n","\n","\n","encoder_checkpoint = \"google/vit-base-patch16-224-in21k\"\n","decoder_checkpoint = \"vinai/phobert-base\"\n","\n","model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n","    encoder_pretrained_model_name_or_path=encoder_checkpoint,\n","    decoder_pretrained_model_name_or_path=decoder_checkpoint,\n",")\n","\n","# ensure that randomly initialized cross-attention layers are added\n","assert model.config.decoder.is_decoder is True\n","assert model.config.decoder.add_cross_attention is True\n","\n","# model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n","# model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"google/vit-base-patch16-224-in21k\", \"aubmindlab/bert-base-arabertv2\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:32.347941Z","iopub.status.busy":"2024-02-28T08:22:32.347638Z","iopub.status.idle":"2024-02-28T08:22:32.353694Z","shell.execute_reply":"2024-02-28T08:22:32.352791Z","shell.execute_reply.started":"2024-02-28T08:22:32.347914Z"},"id":"3IgG58exi5le","trusted":true},"outputs":[],"source":["# set special tokens used for creating the decoder_input_ids from the labels\n","model.config.decoder_start_token_id = tokenizer.cls_token_id\n","model.config.pad_token_id = tokenizer.pad_token_id\n","# make sure vocab size is set correctly\n","model.config.vocab_size = model.config.decoder.vocab_size\n","\n","# set beam search parameters\n","model.config.eos_token_id = tokenizer.sep_token_id\n","model.config.max_length = 64\n","model.config.early_stopping = True\n","model.config.no_repeat_ngram_size = 3\n","model.config.length_penalty = 2.0\n","model.config.num_beams = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:32.355444Z","iopub.status.busy":"2024-02-28T08:22:32.355108Z","iopub.status.idle":"2024-02-28T08:22:32.365173Z","shell.execute_reply":"2024-02-28T08:22:32.364309Z","shell.execute_reply.started":"2024-02-28T08:22:32.355411Z"},"id":"4-J_cT8qjjBT","trusted":true},"outputs":[],"source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    predict_with_generate=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    fp16=True,\n","    output_dir=\"./\",\n","    logging_steps=2,\n","    save_steps=5150,\n","    eval_steps=5150,\n","    report_to=\"none\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:32.366379Z","iopub.status.busy":"2024-02-28T08:22:32.366116Z","iopub.status.idle":"2024-02-28T08:22:32.797866Z","shell.execute_reply":"2024-02-28T08:22:32.796903Z","shell.execute_reply.started":"2024-02-28T08:22:32.366356Z"},"id":"0LEBNvPjjmf-","outputId":"326a739f-f11f-4736-cb27-a9301064cf9d","trusted":true},"outputs":[],"source":["from datasets import load_metric\n","\n","cer_metric = load_metric(\"cer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:32.799486Z","iopub.status.busy":"2024-02-28T08:22:32.799138Z","iopub.status.idle":"2024-02-28T08:22:32.806770Z","shell.execute_reply":"2024-02-28T08:22:32.805889Z","shell.execute_reply.started":"2024-02-28T08:22:32.799455Z"},"id":"tWEq8fTljniO","trusted":true},"outputs":[],"source":["def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"cer\": cer}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:32.808216Z","iopub.status.busy":"2024-02-28T08:22:32.807887Z","iopub.status.idle":"2024-02-28T08:22:32.839597Z","shell.execute_reply":"2024-02-28T08:22:32.838589Z","shell.execute_reply.started":"2024-02-28T08:22:32.808191Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.init(mode=\"disabled\")\n","\n","\n","# os.environ['WANDB_DISABLED'] = 'true'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-28T08:22:32.841601Z","iopub.status.busy":"2024-02-28T08:22:32.841018Z","iopub.status.idle":"2024-02-28T08:51:42.012848Z","shell.execute_reply":"2024-02-28T08:51:42.011984Z","shell.execute_reply.started":"2024-02-28T08:22:32.841573Z"},"id":"McHad6KWjqgC","outputId":"8e052132-b4b4-4823-c1c9-6f96d1009bab","trusted":true},"outputs":[],"source":["from transformers import default_data_collator\n","# instantiate trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    data_collator=default_data_collator,\n",")\n","trainer.train()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
